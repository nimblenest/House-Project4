{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('G:\\\\Homework\\\\House-Project4\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sqlalchemy import create_engine\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from PostgreSQL\n",
    "\n",
    "connection_string = 'postgresql+psycopg2://postgres:D0ntD01t!@localhost:5432/Real_Estate'\n",
    "\n",
    "# Create a database engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Load data from the PostgreSQL table into a pandas DataFrame\n",
    "query = \"SELECT * FROM real_estate\"\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getdummes for county column for analysis purposes\n",
    "county_dummies = pd.get_dummies(df['county'], prefix='county')\n",
    "\n",
    "# concatenate the original df with the new one-hot encoded variables for county\n",
    "#df_encoded = pd.concat([df.drop('county', axis=1), county_dummies], axis=1)\n",
    "df_encoded = pd.concat([df.drop(['county'], axis=1), county_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics for numerical features\n",
    "print(df.describe())\n",
    "\n",
    "# Frequency of categories for a categorical feature like 'County'\n",
    "print(df['county'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selling price histogram\n",
    "sns.histplot(df['selling_price'], kde=True)\n",
    "plt.title('Distribution of Selling Prices')\n",
    "plt.show()\n",
    "\n",
    "# box plot for selling price to visualize outliers\n",
    "sns.boxplot(x=df['selling_price'])\n",
    "plt.title('Box Plot of Selling Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plt for county vs selling price\n",
    "sns.boxplot(x='county', y='selling_price', data=df)\n",
    "plt.title('Selling Price by County')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only numeric columns for the correlation matrix\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# calculate correlation matrix\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "# create heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for a subset of features\n",
    "sns.pairplot(df[['selling_price', 'living_area_sqft', 'lot_sqft', 'beds', 'total_baths', 'age_of_house']])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining whether garage, basement, and waterfront are relevant\n",
    "\n",
    "# selling price vs garage\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='has_garage', y='selling_price', data=df)\n",
    "plt.title('Selling Price vs Garage Presence')\n",
    "plt.show()\n",
    "\n",
    "# selling price vs basement \n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='has_basement', y='selling_price', data=df)\n",
    "plt.title('Selling Price vs Basement Presence')\n",
    "plt.show()\n",
    "\n",
    "# selling price vs waterfront\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='is_waterfront', y='selling_price', data=df)\n",
    "plt.title('Selling Price vs Waterfront Access')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite values in numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number])  # This selects only numeric columns\n",
    "print(np.isfinite(numeric_cols).all())\n",
    "\n",
    "# Check for missing values in the whole DataFrame\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_features = df_encoded.drop(['closing_date', 'city', 'selling_price', 'listing_price', 'mls_number', 'price_diff_from_list', \n",
    "                              'sold_list_ratio', 'year_built', 'full_baths', 'half_baths', 'price_per_sqft', 'age_of_house'], axis=1)\n",
    "X_features = X_features.astype(int)\n",
    "Y_Features = df_encoded['selling_price']\n",
    "\n",
    "print(X_features.dtypes)\n",
    "print(Y_Features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF (Variance Inflation Factor)\n",
    "\n",
    "VIF is a measure used to detect the presence of multicollinearity in a set of predictors in a regression model. Multicollinearity occurs when two or more predictor variables (also known as features or independent variables) are highly correlated with each other. This can cause problems in the regression analysis, including making the model's estimates less reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check for multicollinearity with VIF \n",
    "\n",
    "#drop one county column to prevent infinite results\n",
    "X_features_adjusted = X_features.drop(columns=['county_Alamance'])\n",
    "\n",
    "# Add a constant to the predictors for VIF calculation\n",
    "X = add_constant(X_features_adjusted)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = X.columns\n",
    "\n",
    "# Adjust the VIF calculation to correctly match the DataFrame structure\n",
    "# Also, handle potential divide by zero issues by catching infinite values\n",
    "vif_values = []\n",
    "for i in range(X.shape[1]):\n",
    "    try:\n",
    "        vif = variance_inflation_factor(X.values, i)\n",
    "    except ZeroDivisionError:\n",
    "        vif = float('inf')  # Assign infinity if divide by zero is encountered\n",
    "    vif_values.append(vif)\n",
    "\n",
    "vif_data[\"VIF\"] = vif_values\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "scaled_features = scaler.fit_transform(df[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target variable and features\n",
    "X = X_features.drop(columns='is_waterfront')\n",
    "y = df_encoded['selling_price']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "linear_mse = mean_squared_error(y_test, y_pred_linear)\n",
    "linear_rmse = mean_squared_error(y_test, y_pred_linear, squared=False)\n",
    "linear_r2 = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"Linear Regression MSE: {linear_mse}\")\n",
    "print(f\"Linear Regression RMSE: {linear_rmse}\")\n",
    "print(f\"Linear Regression R^2: {linear_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alisonlove/Bootcamp/House-Project4/house-sales-analysis-ML.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alisonlove/Bootcamp/House-Project4/house-sales-analysis-ML.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# initialize the random forest regressor\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alisonlove/Bootcamp/House-Project4/house-sales-analysis-ML.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m random_forest_model \u001b[39m=\u001b[39m RandomForestRegressor(n_estimators\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alisonlove/Bootcamp/House-Project4/house-sales-analysis-ML.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# train the model on the training data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alisonlove/Bootcamp/House-Project4/house-sales-analysis-ML.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m random_forest_model\u001b[39m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize the random forest regressor\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# train the model on the training data\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest MSE: {rf_mse}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "print(f\"Random Forest R^2: {rf_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature importances\n",
    "feature_importances = pd.DataFrame(random_forest_model.feature_importances_, index=X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "print(feature_importances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-Fold Cross-Validation\n",
    "Perform 10-Fold Cross-Validation to evaluate the model's generalization ability and to mitigate the risk of overfitting\n",
    "\n",
    "This process systematically divides the dataset into ten parts, trains the model on nine of these parts (folds),and evaluates performance on the remaining part. By rotating which part serves as the test set and averaging the results, we obtain a more reliable estimate of how well the model is likely to perform on unseen data, effectively assessing its generalization ability. This method helps ensure that our model's performance is not just a result of overfitting to the training set but indicative of its ability to make accurate predictions across different data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation\n",
    "\n",
    "# initialize the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# perform K-Fold Cross-Validation (let's use K=5 as an example)\n",
    "scores = cross_val_score(rf_model, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# convert scores to positive MSE scores\n",
    "mse_scores = -scores\n",
    "\n",
    "# calculate the RMSE for each fold\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "\n",
    "# calculate average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(f\"Scores: {rmse_scores}\")\n",
    "print(f\"Average RMSE: {avg_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training the model\n",
    "feature_order = list(X_train.columns)\n",
    "print(\"Feature order in model training:\", feature_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model for end-user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `rf_model` is your trained Random Forest model\n",
    "joblib.dump(random_forest_model, 'random_forest_model.joblib')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
